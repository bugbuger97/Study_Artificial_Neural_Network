{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 순환 신경망\n",
        "- 순환 신경망\n",
        "  - 심층 신경망, 합성곱 신경망 등 지금까지 본 내용에서 다룬 신경망들은 입력값이 오직 한 방향으로만 계산되어 출력이 계산되는 구조였음.\n",
        "  - 한쪽 방향으로만 데이터가 흐르는 신경망을 Feed Forward Network(FFN)이라고 함.\n",
        "  - RNN(Recurrent Neural Networks): 매 입력에 대한 inference 혹은 iteration때 마다 은닉층의 값 계산 시 미리 보관하고 있던 값과 입력으로부터 계산된 값을 모두 사용하는 신경망 구조이다.\n",
        "  - RNN에 대해 이해하려면, 이전에는 생각하지 않았던 데이터의 입력 순서 및 각 순서에 따른 index를 고려해야 함. 따라서 RNN은 일반적으로 시간 순서가 있는 데이터에 대해 적용하며 자연어 데이터, 음성 데이터 및 시계열 데이터가 대표적인 예시이다.\n",
        "  - MLP 및 CNN에서는 데이터를 한꺼번에 신경망에 입력해줬으나, RNN은 seqeuce 데이터를 대상으로 하며 한꺼번에 입력하는 것이 아니라 매 time step마다 sequence의 요소 하나씩을 입력함.\n",
        "\n",
        "  - 첫번째 단어가 RNN에 입력되면, 입력 -> 은닉 -> 출력층 순서대로 계산이 수행되며 결과값을 도출하게 됨.\n",
        "    - 각 칸은 층을 나타내며, 뉴런이 여러 개 있을 수도 있고 중간중간 값은 벡터에 해당한다고 볼 수 있음.\n",
        "  - 두번째 단어가 RNN에 입력되면, 입력 -> 은닉 -> 출력층 순서대로 계산이 수행되는 것은 동일하나, 은닉층에서 두 번째 단어에 대한 계산값만 사용하는 것이 아니라 첫번째 단어에 대한 계산을 수행할 때의 은닉층 값 또한 가중치를 곱한 후 사용하는 것을 알 수 있음.\n",
        "    - 이와 같이 index 1에서의 은닉층 값은 index 2에서의 은닉층 값 계산에 영향을 주고, index 2는 index 3에 영향을 주는 등 도미노처럼 이어지게 됨.\n",
        "  - 보통 RNN은 순환하는 계산 구조가 있는 은닉층에 loop edge를 추가하여 표시함.\n",
        "  - 입력 뉴런(노드) 4개, 은닉층 및 출력층 뉴런은 2개가 있다고 가정하면, time step 2에서의 은닉층 뉴런들은 입력 뉴런 및 time step 1에서의 은닉층 뉴런값들을 이용하여 결과값을 도출해냄.\n",
        "  - RNN의 가장 중요한 특성 중 하나는 다양한 길이의 입력 sequence를 처리할 수 있다는 것임.\n",
        "    - CNN은 입력의 크기가 정해져 있는데 반해 RNN은 입력된 sequence의 길이만큼 순환 계산을 반복하면 되므로 다양한 길이에 대해 처리가 가능함.\n",
        "  - 기본적으로 순환 신경망에 입력을 넣을 때마다 매번 그에 해당하는 출력값이 나오지만, 입력값을 어떻게 설정하는지 및 출력값들 중 어떤 것을 유의미하게 해석해서 사용할 것인지에 따라 RNN 활용 방식은 3가지 방식으로 나뉜다.\n",
        "    - one-to-many\n",
        "    - many-to-one\n",
        "    - many-to-many\n",
        "  \n",
        "- one-to-many\n",
        "  - 입력 sequence는 길이가 1이지만, 여기서 나오는 출력을 다시 다음 time step의 입력값으로 사용해서 우리가 원하는 형태의 길이를 갖는 출력을 얻는 방식임.\n",
        "  - ex) 이미지에서 뽑은 특성을 입력받은 후 이를 설명하는 문장을 생성해내는 image captioning이 있다.\n",
        "    - 문장 생성 시 한 time step마다 단어 혹은 토큰 하나씩 생성됨.\n",
        "\n",
        "- many-to-one\n",
        "  - 입력 sequence는 길이가 다양할 수 있고 매 time step마다 결과가 나오긴 하지만 모든 sequence를 다 입력한 다음 나오는 결과만 활용해서 우리가 원하는 예측값을 얻는 방식을 의미함.\n",
        "  - ex) 텍스트 분류\n",
        "\n",
        "- many-to-many\n",
        "  - 입력 sequence에 대해 매 time step마다 나오는 결과를 종합하여 활용하는 방식을 의미함.\n",
        "  - ex) 기계 번역\n",
        "\n",
        "- 순환 신경망 상세 구조\n",
        "  - RNN에서의 입력층, 은닉층, 출력층의 각 데이터 벡터를 x, y, h로 두고 이들을 계산하는데 필요한 가중치들을 아래와 같이 정의함.\n",
        "  - 은닉층에서 출력층으로 가는 연산은 기존 FC와 동일하므로 은닉층의 계산을 중점적으로 살펴보고자 함.\n",
        "  - 특정 time step t에서의 은닉층 벡터는 h_t로 나타내며 h_t 계산에 사용하는 time step (t-1)의 은닉층 벡터는 h_t-1로 나타냄.\n",
        "  - 은닉층에서의 활성함수는 가장 일반적으로 쓰이는 tanh로 가정 (다른 홯성 함수도 적용 가능함.)\n",
        "    - h_t = tanh(W * x_t + U * h_t-1 + b)\n",
        "  - 입력층의 뉴런 개수 및 은닉층의 뉴런 개수를 모두 4개라고 가정하면, 은닉층 연산을 나타낼 수 있음.\n",
        "  - RNN의 은닉층 연산에서는 기본적으로 이전 time step에서의 은닉층 값이 꼭 필요함.\n",
        "  - 이와 같은 은닉층 값을 hidden state라고 부르고, 실제 구현 및 활용 시에는 별도 변수로 관리함.\n",
        "  - sequence가 시작할 때는 미리 계산된 hidden state가 없는 상황인데, 이럴 때는 일반적으로 hidden state를 zero tensor로 초기화한 후 RNN의 예측값 계산을 시작함.\n",
        "\n",
        "# 심층 순환 신경망\n",
        "- 심층 순환 신경망\n",
        "  - 심층 신경망처럼 RNN 또한 여러 층의 은닉층을 포함할 수 있음.\n",
        "  - 각 은닉층은 이전 time step의 값으 참조할 때 서로 같은 층의 값만 참조함.\n",
        "\n",
        "# 양방향 순환 신경망\n",
        "- 양방향 순환 신경망\n",
        "  - 순환 신경망은 기본적으로 time step 순서대로 값을 입력하여 결과값을 생성하지만, 때로는 오히려 time step의 역순으로 분석하는 것도 도움이 될 때가 있다.\n",
        "  - 순방향으로도 결과를 도출하고, 역방향으로도 값들을 입력하여 결과를 도출할 후 이를 합친 것을 최종 결과로 사용하는 RNN 형식을 양방향(bi-directional) 순환 신경망이라고 함.\n",
        "\n",
        "# 장기 의존성 문제 및 LSTM\n",
        "- 장기 의존성 문제\n",
        "  - 지금까지 다룬 형태의 RNN을 가장 단순한 형태의 RNN이라는 의미로 Vanilla RNN이라고 함.\n",
        "  - Vanilla RNN은 이전 입력값들을 분석한 결과를 응축한 형태로 은닉층 값을 계속 변화시켜 나가지만, 그 구조상 어쩔 수 없이 입력 seqeunce의 길이가 길어지면 처음에 분석했던 정보를 나중까지 유지하기는 매우 어려움.\n",
        "    - 만약 t가 매우 크다면, time step 0, 1에서 분석한 정보들은 time step이 t가 되어서는 거의 희석되어 있다고 볼 수 있음.\n",
        "  - Vanilla RNN은 sequence 정보를 처리하는데 유리한 구조이지만, sequence 길이가 길어지면, 서로 거리가 먼 입력값들 사이의 관계를 예측하는데 어려움을 겪음.\n",
        "    - 이와 같은 단점을 보완하기 위해서, Vanilla RNN에 장기 기억을 위한 메모리를 더해준 신경망 구조가 Long Short Term Memory(LSTM) 신경망임.\n",
        "\n",
        "- LSTM\n",
        "  - LSTM의 한 층(혹은 cell이라고도 함)은 Vanilla RNN의 은닉층 값 이외에 cell state라고 불리는 C_t가 추가로 존재함.\n",
        "  - C_t는 장기적으로 관리해야 할 지식들을 따로 관리하는 벡터라고 볼 수 있음.\n",
        "  - LSTM에서는 h_t 및 C_t에 대해 순환 연산 구조를 갖고 있다고 요약 가능함.\n",
        "  - RNN 계열 신경망 구조는 일반적으로 어떤 종류의 RNN cell을 썼는지 명시하고, 전체적인 구조는 Vanilla RNN에서 배웠던 구조처럼 나타냄.\n",
        "  - Vanilla RNN과 LSTM은 hidden state와 output 값이 따로 존재하는데, LSTM의 구조를 조금 더 단순화하여 장기 기억에 능하면서도 따로 Output은 내지 않고 hidden state만 갖도록 하여 속도 및 메모리 효율성을 개선한 GRU라는 cell 형태가 있음.\n",
        "  - 3가지 종류의 RNN cell은 가장 대표적인 RNN cell 구조라고 할 수 있음.\n",
        "    - RNN\n",
        "    - LSTM\n",
        "    - GRU\n",
        "     - GRU 모델 구현\n",
        "        - 일반적으로 many-to-one 구조에서는 마지막 토큰까지 다 분석한 hidden state 또는 output으로부터 전결합층을 연결하여 최종 결과값을 도출함.\n",
        "        - PyTorch의 RNN cell들은 forward를 수행할 때 hidden state를 입력해주어야 함."
      ],
      "metadata": {
        "id": "nzyLYr1Rv13a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------"
      ],
      "metadata": {
        "id": "heL2Ka9lzKgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis using RNN models"
      ],
      "metadata": {
        "id": "jdr748V6zD6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E5ATH9byYWN",
        "outputId": "ea5b2115-4126-43f1-d301-98482e01d6e6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset loading"
      ],
      "metadata": {
        "id": "gKtyS2QVzM6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#zip 파일 현재 폴더로 복사, 중간 부분은 파일명에 따라 변경 필요\n",
        "!cp '/content/drive/MyDrive/IMDB Dataset.csv.zip' ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-SZNTnzy8TT",
        "outputId": "4bae8879-29f3-4f8f-e3bd-8b5b6eac4818"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#압축 해제\n",
        "!unzip 'IMDB Dataset.csv.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8DqmcDkzRQ8",
        "outputId": "9247ad67-d9ee-4579-f9f5-0ab9159fbee9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  IMDB Dataset.csv.zip\n",
            "replace IMDB Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"GPU not available, CPU used\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9-WYyxgzX37",
        "outputId": "a42a61f0-6027-4be4-8600-8b536fda791b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_csv = 'IMDB Dataset.csv'\n",
        "df = pd.read_csv(base_csv)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x1LxS0oczd2j",
        "outputId": "ec273ff1-b4d9-44c7-b4e0-20c5000e72a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1ef4473-b334-4e74-a13e-5b6da82cb6f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1ef4473-b334-4e74-a13e-5b6da82cb6f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1ef4473-b334-4e74-a13e-5b6da82cb6f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1ef4473-b334-4e74-a13e-5b6da82cb6f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-427eb36b-05bb-445c-8ebe-b2bd7859ed61\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-427eb36b-05bb-445c-8ebe-b2bd7859ed61')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-427eb36b-05bb-445c-8ebe-b2bd7859ed61 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-process the dataset"
      ],
      "metadata": {
        "id": "Q4L-WClY03Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df['review'].values, df['sentiment'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(f'shape of train data is {x_train.shape}')\n",
        "print(f'shape of test data is {x_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4xsobjV0cwU",
        "outputId": "d755aeb7-88a8-47ec-9e88-d11a9849c745"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train data is (40000,)\n",
            "shape of test data is (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_string(s):\n",
        "  # Remove all non-word characters (everything except numbers and letters)\n",
        "  s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "  # Replace all runs of whitespaces with no space\n",
        "  s = re.sub(r\"\\s+\", '', s)\n",
        "  # replace digits with no space\n",
        "  s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "  return s"
      ],
      "metadata": {
        "id": "7sptpY3W1mGM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x_train,y_train,x_val,y_val):\n",
        "  word_list = []\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  for sent in x_train:\n",
        "    for word in sent.lower().split():\n",
        "      word = preprocess_string(word)\n",
        "      if word not in stop_words and word != '':\n",
        "        word_list.append(word)\n",
        "\n",
        "  corpus = Counter(word_list)\n",
        "  # sorting on the basis of most common words\n",
        "  corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
        "  # creating a dict\n",
        "  onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
        "\n",
        "  # tokenize\n",
        "  final_list_train,final_list_test = [],[]\n",
        "  for sent in x_train:\n",
        "    final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() if preprocess_string(word) in onehot_dict.keys()])\n",
        "  for sent in x_val:\n",
        "    final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() if preprocess_string(word) in onehot_dict.keys()])\n",
        "\n",
        "  encoded_train = [1 if label =='positive' else 0 for label in y_train]\n",
        "  encoded_test = [1 if label =='positive' else 0 for label in y_val]\n",
        "  return np.array(final_list_train, dtype=object), np.array(encoded_train),np.array(final_list_test, dtype=object), np.array(encoded_test),onehot_dict"
      ],
      "metadata": {
        "id": "w8D6AS3F1waj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize 함수 실행\n",
        "x_train, y_train, x_test, y_test, vocab = tokenize(x_train, y_train, x_test, y_test)\n",
        "print(f'Length of vocabulary is {len(vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x39TEh0j2Q9s",
        "outputId": "2f75570b-7c69-4a12-969a-de2e1daea816"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of vocabulary is 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rev_len = [len(i) for i in x_train]\n",
        "pd.Series(rev_len).hist()\n",
        "plt.show()\n",
        "pd.Series(rev_len).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "asSSDsan3Ad8",
        "outputId": "62aae746-4874-4a40-8f44-31385e0d3cc3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    40000.000000\n",
              "mean        69.089175\n",
              "std         47.854883\n",
              "min          0.000000\n",
              "25%         39.000000\n",
              "50%         54.000000\n",
              "75%         84.000000\n",
              "max        651.000000\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>69.089175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47.854883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>39.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>54.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>84.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>651.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_(sentences, seq_len):\n",
        "  features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "  for ii, review in enumerate(sentences):\n",
        "    if len(review) != 0:\n",
        "      features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "  return features\n",
        "\n",
        "#train과 test에 대해서 padding_ 함수 실행, seq_len = 200\n",
        "x_train_pad = padding_(x_train, 200)\n",
        "x_test_pad = padding_(x_test, 200)"
      ],
      "metadata": {
        "id": "m-E0FSEQ32_A"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "KtNfWoxV4IYE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print('Sample input: \\n', sample_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHdbTDjD50LF",
        "outputId": "dc4a19b6-bf9a-4a85-8a6c-bcda5c71fb73"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[  0,   0,   0,  ..., 107, 316,  97],\n",
            "        [  0,   0,   0,  ...,  11,  45,  25],\n",
            "        [  0,   0,   0,  ..., 826, 375, 130],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  32,   2, 482],\n",
            "        [  0,   0,   0,  ..., 306, 171, 211],\n",
            "        [  0,   0,   0,  ..., 447,  98, 446]])\n",
            "Sample input: \n",
            " tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
            "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "        0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU_model(nn.Module):\n",
        "  def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, device):\n",
        "    super(GRU_model, self).__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.device = device\n",
        "\n",
        "    self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "    self.gru = nn.GRU(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n",
        "    self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embed(x)\n",
        "    h_0 = self._init_state(batch_size=x.size(0))\n",
        "    x, _ = self.gru(x, h_0)\n",
        "    h_t = x[:, -1, :]\n",
        "    logit = self.out(h_t)\n",
        "    return logit\n",
        "\n",
        "  def _init_state(self, batch_size):\n",
        "    new_state = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n",
        "    return new_state"
      ],
      "metadata": {
        "id": "2GPO6vvG53aU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 1\n",
        "vocab_size = len(vocab) + 1  # extra 1 for <pad>\n",
        "hidden_dim = 128\n",
        "embed_dim = 100\n",
        "n_classes = 2\n",
        "\n",
        "#GRU 모델 객체 생성\n",
        "model = GRU_model(n_layers, hidden_dim, vocab_size, embed_dim, n_classes, device).to(device)"
      ],
      "metadata": {
        "id": "cm4ub2Jg8Ve1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and evaluation"
      ],
      "metadata": {
        "id": "6Kf7oCk2841Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, data_loader):\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  for i, (x, y) in enumerate(data_loader):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logit = model(x)\n",
        "    loss = criterion(logit, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item() * x.size(0)\n",
        "  return train_loss / len(data_loader.dataset)\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "  model.eval()\n",
        "  corrects, total_loss = 0, 0\n",
        "  for i, (x, y) in enumerate(data_loader):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    logit = model(x)\n",
        "    corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "  size = len(data_loader.dataset)\n",
        "  avg_accuracy = 100.0 * corrects / size\n",
        "  return avg_accuracy"
      ],
      "metadata": {
        "id": "bly3fw6u84D9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "lr = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for e in range(1, num_epochs+1):\n",
        "  train_loss = train(model, criterion, optimizer, train_loader)\n",
        "  test_accuracy = evaluate(model, test_loader)\n",
        "  print(\"[Epoch: %d] train loss : %5.2f | test accuracy : %5.2f\" % (e, train_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgwIFaRC9JHV",
        "outputId": "1ef1abd8-1c3f-468a-8545-f7d576399c58"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1] train loss :  0.45 | test accuracy : 84.52\n",
            "[Epoch: 2] train loss :  0.33 | test accuracy : 85.36\n",
            "[Epoch: 3] train loss :  0.29 | test accuracy : 86.08\n",
            "[Epoch: 4] train loss :  0.25 | test accuracy : 86.44\n",
            "[Epoch: 5] train loss :  0.21 | test accuracy : 86.25\n",
            "[Epoch: 6] train loss :  0.16 | test accuracy : 85.05\n",
            "[Epoch: 7] train loss :  0.11 | test accuracy : 85.15\n",
            "[Epoch: 8] train loss :  0.08 | test accuracy : 84.80\n",
            "[Epoch: 9] train loss :  0.05 | test accuracy : 84.46\n",
            "[Epoch: 10] train loss :  0.05 | test accuracy : 84.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM model code"
      ],
      "metadata": {
        "id": "5NOVEmqr9TAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_model(nn.Module):\n",
        "  def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, device):\n",
        "    super(LSTM_model, self).__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.device = device\n",
        "\n",
        "    self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "    self.lstm = nn.LSTM(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n",
        "    self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embed(x)\n",
        "    h_0 = self._init_state(batch_size=x.size(0))\n",
        "    x, _ = self.lstm(x, h_0)\n",
        "    h_t = x[:,-1,:]\n",
        "    logit = self.out(h_t)\n",
        "    return logit\n",
        "\n",
        "  def _init_state(self, batch_size):\n",
        "    new_cell_state = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n",
        "    new_hidden_state = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n",
        "    return (new_hidden_state, new_cell_state)"
      ],
      "metadata": {
        "id": "uULJvPDg9LEN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM training and evaluation"
      ],
      "metadata": {
        "id": "jG-5Auv0_4IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM 모델 객체 생성\n",
        "model = LSTM_model(n_layers, hidden_dim, vocab_size, embed_dim, n_classes, device).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "for e in range(1, num_epochs+1):\n",
        "  train_loss = train(model, criterion, optimizer, train_loader)\n",
        "  test_accuracy = evaluate(model, test_loader)\n",
        "  print(\"[Epoch: %d] train loss : %5.2f | test accuracy : %5.2f\" % (e, train_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mIojAZi_hxl",
        "outputId": "1082aa56-456c-43cb-d82d-e0e0925f6f75"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1] train loss :  0.47 | test accuracy : 80.69\n",
            "[Epoch: 2] train loss :  0.37 | test accuracy : 84.35\n",
            "[Epoch: 3] train loss :  0.32 | test accuracy : 84.67\n",
            "[Epoch: 4] train loss :  0.29 | test accuracy : 84.57\n",
            "[Epoch: 5] train loss :  0.26 | test accuracy : 85.37\n",
            "[Epoch: 6] train loss :  0.22 | test accuracy : 84.78\n",
            "[Epoch: 7] train loss :  0.17 | test accuracy : 85.35\n",
            "[Epoch: 8] train loss :  0.13 | test accuracy : 84.33\n",
            "[Epoch: 9] train loss :  0.08 | test accuracy : 84.67\n",
            "[Epoch: 10] train loss :  0.06 | test accuracy : 84.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vanilla RNN model code"
      ],
      "metadata": {
        "id": "uqyPwWMzBAcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_model(nn.Module):\n",
        "  def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, device):\n",
        "    super(RNN_model, self).__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.device = device\n",
        "\n",
        "    self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "    self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n",
        "    self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embed(x)\n",
        "    h_0 = self._init_state(batch_size=x.size(0))\n",
        "    x, _ = self.rnn(x, h_0)\n",
        "    h_t = x[:,-1,:]\n",
        "    logit = self.out(h_t)\n",
        "    return logit\n",
        "\n",
        "  def _init_state(self, batch_size):\n",
        "    new_state = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n",
        "    return new_state"
      ],
      "metadata": {
        "id": "4eaOVN-mAOwV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y#vanilla RNN 모델 객체 생성\n",
        "model = RNN_model(n_layers, hidden_dim, vocab_size, embed_dim, n_classes, device).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for e in range(1, num_epochs+1):\n",
        "  train_loss = train(model, criterion, optimizer, train_loader)\n",
        "  test_accuracy = evaluate(model, test_loader)\n",
        "  print(\"[Epoch: %d] train loss : %5.2f | test accuracy : %5.2f\" % (e, train_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM4nOnWvUKdE",
        "outputId": "a7c60952-98e8-4d61-b2ce-53dda0e373ee"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1] train loss :  0.58 | test accuracy : 74.48\n",
            "[Epoch: 2] train loss :  0.59 | test accuracy : 59.36\n",
            "[Epoch: 3] train loss :  0.63 | test accuracy : 56.25\n",
            "[Epoch: 4] train loss :  0.66 | test accuracy : 60.34\n",
            "[Epoch: 5] train loss :  0.63 | test accuracy : 56.93\n",
            "[Epoch: 6] train loss :  0.64 | test accuracy : 66.14\n",
            "[Epoch: 7] train loss :  0.60 | test accuracy : 72.25\n",
            "[Epoch: 8] train loss :  0.60 | test accuracy : 65.86\n",
            "[Epoch: 9] train loss :  0.55 | test accuracy : 66.88\n",
            "[Epoch: 10] train loss :  0.60 | test accuracy : 68.54\n"
          ]
        }
      ]
    }
  ]
}